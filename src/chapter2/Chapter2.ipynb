{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# Chapter 2: Working with Data",
   "id": "2bd865e9deb7c641"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will first download the data if it does't exist, we want the text in the file the-verdict.txt",
   "id": "6b889e712c44ed86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:34:49.299938Z",
     "start_time": "2025-08-18T05:34:49.296627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from src.chapter2.data_sampling import first_batch\n",
    "\n",
    "if os.path.exists(\"./data/the-verdict.txt\"):\n",
    "    print(\"Data already exists\")\n",
    "else:\n",
    "    import requests\n",
    "    data = requests.get(\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch02/01_main-chapter-code/the-verdict.txt\")\n",
    "    if data.status_code == 200:\n",
    "        os.makedirs(\"./data\", exist_ok=True)\n",
    "        with open(\"./data/the-verdict.txt\", \"w\") as f:\n",
    "            f.write(data.text)\n",
    "        print(\"Data downloaded successfully\")\n",
    "    else:\n",
    "        print(\"Failed to download data\")"
   ],
   "id": "4a8647b24fe2984f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will now read the data from the file",
   "id": "a4b70f3e158429c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:40:55.609888Z",
     "start_time": "2025-08-18T05:40:55.604360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ],
   "id": "ad2e04c998590864",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:40:11.840332Z",
     "start_time": "2025-08-18T05:40:11.838933Z"
    }
   },
   "cell_type": "markdown",
   "source": "We will now split this text using the below regex (no need to memorize this regex)",
   "id": "c98183c328d68027"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:42:42.819181Z",
     "start_time": "2025-08-18T05:42:42.812890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item for item in preprocessed if item.strip() != '']\n",
    "print(\"Total number of tokens:\", len(preprocessed))\n",
    "print(preprocessed[:30])"
   ],
   "id": "26ed1223dbd1ef7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 4690\n",
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:41:57.521688Z",
     "start_time": "2025-08-18T05:41:57.514706Z"
    }
   },
   "cell_type": "markdown",
   "source": "We now create token ids for these tokens by assigning a unique integer to each token.",
   "id": "f4dc11dc9b1e0f3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:48:32.221747Z",
     "start_time": "2025-08-18T05:48:32.217163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "print(\"Vocab size is:\", vocab_size)\n",
    "vocab = {token: idx for idx, token in enumerate(all_words)}  # This is a dictionary mapping tokens to their ids\n",
    "for token, idx in list(vocab.items())[:51]:\n",
    "    print(f\"({token:>10s} -> {idx:>3d})\")"
   ],
   "id": "8fa07029255ebc56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is: 1130\n",
      "(         ! ->   0)\n",
      "(         \" ->   1)\n",
      "(         ' ->   2)\n",
      "(         ( ->   3)\n",
      "(         ) ->   4)\n",
      "(         , ->   5)\n",
      "(        -- ->   6)\n",
      "(         . ->   7)\n",
      "(         : ->   8)\n",
      "(         ; ->   9)\n",
      "(         ? ->  10)\n",
      "(         A ->  11)\n",
      "(        Ah ->  12)\n",
      "(     Among ->  13)\n",
      "(       And ->  14)\n",
      "(       Are ->  15)\n",
      "(      Arrt ->  16)\n",
      "(        As ->  17)\n",
      "(        At ->  18)\n",
      "(        Be ->  19)\n",
      "(     Begin ->  20)\n",
      "(Burlington ->  21)\n",
      "(       But ->  22)\n",
      "(        By ->  23)\n",
      "(     Carlo ->  24)\n",
      "(   Chicago ->  25)\n",
      "(    Claude ->  26)\n",
      "(      Come ->  27)\n",
      "(     Croft ->  28)\n",
      "( Destroyed ->  29)\n",
      "(Devonshire ->  30)\n",
      "(       Don ->  31)\n",
      "(   Dubarry ->  32)\n",
      "(  Emperors ->  33)\n",
      "(  Florence ->  34)\n",
      "(       For ->  35)\n",
      "(   Gallery ->  36)\n",
      "(    Gideon ->  37)\n",
      "(   Gisburn ->  38)\n",
      "(  Gisburns ->  39)\n",
      "(   Grafton ->  40)\n",
      "(     Greek ->  41)\n",
      "(   Grindle ->  42)\n",
      "(  Grindles ->  43)\n",
      "(       HAD ->  44)\n",
      "(       Had ->  45)\n",
      "(      Hang ->  46)\n",
      "(       Has ->  47)\n",
      "(        He ->  48)\n",
      "(       Her ->  49)\n",
      "(    Hermia ->  50)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now lets define a simple tokenizer that encapsulates this functionality, given a vocab, it should be able to conver the given text to tokens, that is encode and decode tokens to text\n",
   "id": "f09ad9d4961b1f9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:57:35.484032Z",
     "start_time": "2025-08-18T05:57:35.479506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {v:k for k, v in vocab.items()}\n",
    "\n",
    "\n",
    "    def encode(self, text):\n",
    "        processed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        processed = [item for item in processed if item.strip() != '']\n",
    "        return [self.str_to_int[token] for token in processed]\n",
    "\n",
    "    def decode(self, token_ids):\n",
    "        text =  \" \".join([self.int_to_str[token_id] for token_id in token_ids])\n",
    "        # Remove the preceding space before the punctuations\n",
    "        return re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)"
   ],
   "id": "1573c1fedaba31d5",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:57:35.999315Z",
     "start_time": "2025-08-18T05:57:35.996031Z"
    }
   },
   "cell_type": "markdown",
   "source": "Lets test the implemented code with a sample text",
   "id": "a79dfd793ca8331c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:58:32.971922Z",
     "start_time": "2025-08-18T05:58:32.967520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted, you know,\"\n",
    "       Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "SimpleTokenizerV1(vocab)\n",
    "print(ids)\n",
    "print(tokenizer.decode(ids))\n",
    "\n",
    "# This code will not work as we wont find keys for missing tokens\n",
    "# text = \"Hello, do you like tea?\"\n",
    "# print(tokenizer.encode(text))"
   ],
   "id": "eebea3f9ca0ecc6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n",
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T06:05:26.071257Z",
     "start_time": "2025-08-18T06:05:26.066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "print(f\"New vocab size is {len(vocab.items())}\")\n",
    "for item in list(vocab.items())[-5:]:\n",
    "    print(f\"({item[0]:>10s} -> {item[1]:>3d})\")"
   ],
   "id": "b0367cd157033a4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New vocab size is 1132\n",
      "(   younger -> 1127)\n",
      "(      your -> 1128)\n",
      "(  yourself -> 1129)\n",
      "(<|endoftext|> -> 1130)\n",
      "(   <|unk|> -> 1131)\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will now create a V2 tokenizer that is same as V1 but handles the unknown tokens and accepts the concatenated text as input seperated by ``<endoftext>`` token",
   "id": "d9653360c33efff9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T06:09:16.495457Z",
     "start_time": "2025-08-18T06:09:16.490862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {v:k for k, v in vocab.items()}\n",
    "        self.unknown_token = \"<|unk|>\"\n",
    "\n",
    "\n",
    "    def encode(self, text):\n",
    "        processed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        processed = [item for item in processed if item.strip() != '']\n",
    "        return [self.str_to_int[token] if token in self.str_to_int else self.str_to_int[self.unknown_token] for token in processed]\n",
    "\n",
    "    def decode(self, token_ids):\n",
    "        text =  \" \".join([self.int_to_str[token_id] for token_id in token_ids])\n",
    "        # Remove the preceding space before the punctuations\n",
    "        return re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)"
   ],
   "id": "e4154c40cc4a7ae0",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lets test this new tomenizer",
   "id": "a0ba1b5aab7bf4c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T06:10:49.739520Z",
     "start_time": "2025-08-18T06:10:49.737352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)\n",
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "print(tokenizer.encode(text))\n",
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ],
   "id": "5677b0a63ab066b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n",
      "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]\n",
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Byte Pair",
   "id": "6109c0f29b446c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T05:13:22.347177Z",
     "start_time": "2025-08-19T05:13:22.342147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from importlib.metadata import version\n",
    "print(\"tiktoken version: \",version(\"tiktoken\"))"
   ],
   "id": "acc5505d3c78f3ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version:  0.8.0\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create the gpt-2 tokenizer and use it",
   "id": "a3d6c4eaefbe76e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T04:45:25.252329Z",
     "start_time": "2025-08-19T04:45:25.249827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = (\n",
    "            \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "             \"of someunknownPlace.\"\n",
    ")\n",
    "print(f\"Text is: \\n{text}\")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(f\"Total vocabulary size for {tokenizer.name} is {tokenizer.n_vocab}\")\n",
    "print(\"Encoded tokens are: \")\n",
    "print(integers)\n",
    "print(\"Decoding the above encoded tokens give:\")\n",
    "print(tokenizer.decode(integers))"
   ],
   "id": "723f75759e14d9ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text is: \n",
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n",
      "Total vocabulary size for gpt2 is 50257\n",
      "Encoded tokens are: \n",
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n",
      "Decoding the above encoded tokens give:\n",
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data sampling with a sliding window",
   "id": "48a94529558bcd7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Start by encoding the entire text from the text file",
   "id": "37428c3efeca02da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T05:00:10.161790Z",
     "start_time": "2025-08-19T05:00:10.153060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"./data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(f\"Total number of tokens in the text: {len(enc_text)}\")"
   ],
   "id": "e3581aa5d6e4a139",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in the text: 5145\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Simple example of how the next word prediction data can be generated by creating two variables x and y",
   "id": "d2072e0ff981de71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T05:06:56.672163Z",
     "start_time": "2025-08-19T05:06:56.664996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "enc_sample = enc_text[50:]\n",
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size + 1]\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")\n",
    "print(\"-\"*50)\n",
    "for i in range(1,context_size + 1):\n",
    "  context = enc_sample[:i]\n",
    "  desired = enc_sample[i]\n",
    "  print(context, \"---->\", desired)\n",
    "print(\"-\"*50)\n",
    "print(\"\\t\\t\\tDecoded text\")\n",
    "print(\"-\"*50)\n",
    "for i in range(1,context_size + 1):\n",
    "  context = enc_sample[:i]\n",
    "  desired = enc_sample[i]\n",
    "  print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ],
   "id": "d6192294eaf119fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n",
      "--------------------------------------------------\n",
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n",
      "--------------------------------------------------\n",
      "\t\t\tDecoded text\n",
      "--------------------------------------------------\n",
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lets create a Pytorch data loader",
   "id": "9e87170a9543dc59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c28caed1a43c5ccf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T00:39:56.295379Z",
     "start_time": "2025-08-20T00:39:56.292135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        tokenized_text = tokenizer.encode(txt)\n",
    "        for i in range(0, len(tokenized_text) - max_length, stride):\n",
    "            input_chunk = tokenized_text[i:i + max_length]\n",
    "            target_chunk = tokenized_text[i + 1:i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "    import tiktoken\n",
    "    gpt2_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, gpt2_tokenizer, max_length, stride)\n",
    "    return DataLoader(dataset=dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle, drop_last=drop_last)\n"
   ],
   "id": "f993983fd16d7882",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T00:39:57.059941Z",
     "start_time": "2025-08-20T00:39:56.843337Z"
    }
   },
   "cell_type": "markdown",
   "source": "Now instantiate this dataloader with the text file we have",
   "id": "b7c6e9c5fce441c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T00:41:28.705762Z",
     "start_time": "2025-08-20T00:41:28.654150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(f\"First batch {first_batch}\")"
   ],
   "id": "e1779065f00234c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch [tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:20:12.471800Z",
     "start_time": "2025-08-20T05:20:12.463103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "second_batch = next(data_iter)\n",
    "print(f\"First batch {second_batch}\")\n"
   ],
   "id": "c8c1d2f589c9deb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch [tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lets look at  larger batch size and stride",
   "id": "ba9d451059de5bd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:22:12.735300Z",
     "start_time": "2025-08-20T05:22:12.714154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=4, stride=4,\n",
    "    shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)\n"
   ],
   "id": "90be72862f5db07b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Creating token embeddings",
   "id": "6eb338213c37da21"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Assume a vocab of 6 words (GPT has 50,257) and each embedding is 3 dimension (GPT-3 has 12288 dimensions). The embeddings are essentially lookup tables of size (vocab_size, embedding_dim) where vocab_size is the number of unique tokens and embedding_dim is the dimension of the embedding vector for each token. In this case it will have the shape of (6, 3). The embedding matrix is initialized randomly and then trained during the training process.",
   "id": "84efd067b87b1a26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:31:35.644790Z",
     "start_time": "2025-08-20T05:31:35.618545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokens\n",
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(f\"Embedding layer weights are: {embedding_layer.weight}\")"
   ],
   "id": "cb61dd815807374c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer weights are: Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:33:03.007117Z",
     "start_time": "2025-08-20T05:33:03.003759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Simply lookup the embeddings for the input tokens\n",
    "embedding_layer(input_ids)"
   ],
   "id": "e38d9c2e983e8dec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2753, -0.2010, -0.1606],\n",
       "        [-0.4015,  0.9666, -1.1481],\n",
       "        [-2.8400, -0.7849, -1.4096],\n",
       "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "While this lookup works, the position information of the tokens is lost. To retain the position information, we will use positional embeddings. The positional embeddings are added to the token embeddings to create a final embedding that contains both the token and position information.\n",
    "\n",
    "Two types of position embeddings are\n",
    "1. Absolute positional embeddings: where each position has a unique embedding vector.\n",
    "2. Relative positional embeddings: where the position of a token is relative to the other tokens in the sequence.\n",
    "\n",
    "OpenAI's GPT models use absolute positional embeddings. The positional embeddings are added to the token embeddings to create a final embedding that contains both the token and position information. These embeddings are learned during the training process and are not fixed.\n",
    "\n",
    "Let us now create the embeddings layer for the vocabulary size same as GPT but the output dimension of 256"
   ],
   "id": "e0bc034f98c3ef79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:44:16.108726Z",
     "start_time": "2025-08-20T05:44:15.967375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ],
   "id": "51bbefe2399dd97a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lets get a batch of input ids and get the embeddings for these input ids",
   "id": "679d76250fdea193"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:48:09.170474Z",
     "start_time": "2025-08-20T05:48:09.159501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length, stride=4,\n",
    "    shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nToken IDs shape:\\n\", inputs.shape)\n",
    "\n",
    "# Lookup embeddings for the input tokens\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(f\"\\nToken Embeddings shape:\\n{token_embeddings.shape}\")\n"
   ],
   "id": "70bee1958facb62d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Token IDs shape:\n",
      " torch.Size([8, 4])\n",
      "\n",
      "Token Embeddings shape:\n",
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We will need another embeddings to represent the positions. The number of distinct embeddings will be same as the number of fixed tokens in an input sequence. Each of these will have the same dimension as the token embedding itself as we will add these two embeddings together to get the final embedding.\n",
    "\n",
    "Thus in our case since the max_length, which i same as context_length is 4, we will have 4 positional embeddings, each of dimension 256."
   ],
   "id": "ec595c44b08cb55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:54:17.778157Z",
     "start_time": "2025-08-20T05:54:17.771847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(f\"Positional Embedding layer weights are: {pos_embeddings.shape}\")"
   ],
   "id": "54f5dff2365fe480",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Embedding layer weights are: torch.Size([4, 256])\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:57:21.284157Z",
     "start_time": "2025-08-20T05:57:21.282237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Notice how we are adding a tensor of shape (4, 256) to a tensor of shape (8, 4, 256). This is possible because of broadcasting in PyTorch.\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(f\"Input Embeddings shape: {input_embeddings.shape}\")"
   ],
   "id": "46e447292a19243f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Embeddings shape: torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "18a74b3912aea0cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
