{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# Pretraining on unlabeled data\n",
    "\n",
    "In this notebook we will look at the following\n",
    "\n",
    "![test](./ThisChapter.png)\n",
    "\n",
    "We will take (copy over) the ``GPTModel``(and all other dependencies)  we coded previously in this notebook\n",
    "\n"
   ],
   "id": "d3ce4d451a613ef2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:02:53.405844Z",
     "start_time": "2025-09-24T06:02:53.397255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from numpy.f2py.rules import options\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # This is new, we will add an optional Linear layer to project the output.\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in_ca = x.shape\n",
    "        keys_mha = self.W_key(x)       # (b, num_tokens, d_out)\n",
    "        values_mha = self.W_value(x)   # (b, num_tokens, d_out)\n",
    "        queries_mha = self.W_query(x)  # (b, num_tokens, d_out)\n",
    "\n",
    "        # d_out is same as num_heads * head_dim\n",
    "        # view reshapes the tensor without changing its data, in this case we project the\n",
    "        # last d_out dimension to (num_heads, head_dim)\n",
    "        keys_mha = keys_mha.view(b, num_tokens, self.num_heads, self.head_dim) # (b, num_tokens, num_heads, head_dim)\n",
    "        values_mha = values_mha.view(b, num_tokens, self.num_heads, self.head_dim) # (b, num_tokens, num_heads, head_dim)\n",
    "        queries_mha = queries_mha.view(b, num_tokens, self.num_heads, self.head_dim) # (b, num_tokens, num_heads, head_dim)\n",
    "\n",
    "        # To calculation the attention score, we need the last two dimensions to be num_tokens and head_dim\n",
    "        # thus we need to transpose the 1st and 2nd dimensions\n",
    "        queries_mha.transpose_(1, 2)  # (b, num_heads, num_tokens, head_dim)\n",
    "        keys_mha.transpose_(1, 2)     # (b, num_heads, num_tokens, head_dim)\n",
    "        values_mha.transpose_(1, 2)   # (b, num_heads, num_tokens, head_dim)\n",
    "\n",
    "         # Let calculate the attention scores, this is the dot product of queries and keys\n",
    "        attn_scores_mha = queries_mha @ keys_mha.transpose(-2, -1) # (b, num_heads, num_tokens, num_tokens)\n",
    "\n",
    "        # Apply the mask, the dimensions of the attn scores are still (b, num_heads, num_tokens, num_tokens)\n",
    "        #  the mask is 2D and is applied to the last two dimensions only\n",
    "        attn_scores_mha.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf) #(b, num_heads, num_tokens, num_tokens)\n",
    "        attn_weights_mha = torch.softmax(attn_scores_mha / self.head_dim ** 0.5, dim=-1) #(b, num_heads, num_tokens, num_tokens)\n",
    "        # Apply dropout to the attention weights\n",
    "        attn_weights_mha = self.dropout(attn_weights_mha) # (b, num_heads, num_tokens, num_tokens)\n",
    "        # attn_weights_mha @ values_mha gives (b, num_heads, num_tokens, head_dim)\n",
    "        # We need to transpose the 1st and 2nd (both 0 indexed) dimensions to get (b, num_tokens, num_heads, head_dim)\n",
    "        context_vecs_mha = (attn_weights_mha @ values_mha).transpose(1,2) # (b, num_tokens, num_heads, head_dim)\n",
    "        # We will reshape the context vectors back to (b, num_tokens, d_out) where d_out = num_heads * head_dim\n",
    "        context_vecs_mha = context_vecs_mha.contiguous().view(b, num_tokens, self.d_out) # (b, num_tokens, d_out)\n",
    "        # Finally we will project the output using the out_proj layer\n",
    "        context_vecs_mha = self.out_proj(context_vecs_mha)\n",
    "        return context_vecs_mha\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim, eps = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_batch = torch.mean(x, dim=-1, keepdim=True)\n",
    "        # unbiased=False means we do not use Bessel's correction, that is, we divide by N instead of N-1 (basel's correction)\n",
    "        var_batch = torch.var(x, dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean_batch) / torch.sqrt(var_batch + self.eps)\n",
    "        return norm_x * self.scale + self.shift\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg, hidden_layer_dim_factor = 4):\n",
    "        super().__init__()\n",
    "        emb_dim = cfg[\"emb_dim\"]\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(emb_dim, hidden_layer_dim_factor * emb_dim),\n",
    "            GELU(),\n",
    "            nn.Linear(hidden_layer_dim_factor * emb_dim, emb_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, in_batch):\n",
    "        return self.layers(in_batch)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.dropout_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.dropout_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        return self.out_head(x)"
   ],
   "id": "bedf7560edc7c1b0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Below we will instantiate the GPT model with the configuration of the smallest GPT-2 model (124M parameters), however we will reduce the context length to 256 for faster training. Additionally we will define two methods ``text_to_token_ids`` and ``token_ids_to_text``",
   "id": "7f5be1d8dc72dd1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:02:54.203477Z",
     "start_time": "2025-09-24T06:02:53.411598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,  # we will use a smaller context length for faster training, original is 1024\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ],
   "id": "382dd9cda9bebe55",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:02.141821Z",
     "start_time": "2025-09-24T06:02:54.212409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "\n",
    "def generate_text_simple(model, idx,\n",
    "                          max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Take the context_size tokens to predict the next token\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():  # No need to track gradients\n",
    "            logits = model(idx_cond) # (batch_size, context_size, vocab_size)\n",
    "        # Take the last generated token for this is the next token\n",
    "        logits = logits[:, -1, :] # (batch_size, vocab_size)\n",
    "        probs = torch.softmax(logits, dim=-1) # (batch_size, vocab_size)\n",
    "        idx_next = torch.argmax(probs, dim=-1, keepdim=True) # (batch_size, 1)\n",
    "        idx = torch.cat((idx, idx_next), dim=-1) # (batch_size, current_seq_len + 1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    return torch.tensor(encoded).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    token_ids = token_ids.squeeze(0).tolist()  # Remove batch dimension and convert to list\n",
    "    return tokenizer.decode(token_ids)\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "    )\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "46d1ee470d38a5dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T04:45:08.658682Z",
     "start_time": "2025-09-11T04:45:08.656379Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "We can see that the output is not very meaningful, this is because the model is not trained yet. However all our required components are in place.\n",
    "\n",
    "We will next look at loss metric for the generated output\n",
    "\n",
    "### Calculating the text generation loss\n",
    "\n",
    "![test](./TextGenerationSummary.png)\n"
   ],
   "id": "f82a3d839c58b1f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:02.199167Z",
     "start_time": "2025-09-24T06:03:02.196069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "input_text1 = \"every effort moves\"\n",
    "input_text2 = \"I really like\"\n",
    "\n",
    "expected_output_text1 = \" effort moves you\"\n",
    "expected_output_text2 = \" really like chocolate\"\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "inputs = torch.vstack([text_to_token_ids(input_text1, tokenizer), text_to_token_ids(input_text2, tokenizer)])\n",
    "print(f\"Input token ids are:\\n{inputs}\")\n",
    "\n",
    "targets = torch.vstack([text_to_token_ids(expected_output_text1, tokenizer), text_to_token_ids(expected_output_text2, tokenizer)])\n",
    "print(f\"Output token ids are:\\n{targets}\")\n"
   ],
   "id": "6dfe1980630bc07f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token ids are:\n",
      "tensor([[16833,  3626,  6100],\n",
      "        [   40,  1107,   588]])\n",
      "Output token ids are:\n",
      "tensor([[ 3626,  6100,   345],\n",
      "        [ 1107,   588, 11311]])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lets feed the inputs to the model and get the logits",
   "id": "ac882eb3a43a29e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:02.271420Z",
     "start_time": "2025-09-24T06:03:02.211100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "print(f\"Logits shape: {logits.shape}\")\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(f\"Probs shape: {probas.shape}\")"
   ],
   "id": "1012c08f1095a8d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Probs shape: torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "There are 2 batches, each with 3 tokens and each token as a probability distribution over the vocabulary of size 50257. What we need is the maximum probability for each of these 3 tokens in 2 batches.\n",
    "\n",
    "Notice how we retain the third dimension by using ``keepdim=True``, if this wasn't provided the the result would have been of shape (2, 3) instead of (2, 3, 1)"
   ],
   "id": "78f9af8f703e3407"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:02.279953Z",
     "start_time": "2025-09-24T06:03:02.277484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(f\"token_ids are {token_ids} \\n\\nand has shape {token_ids.shape}\")"
   ],
   "id": "4fd7ef63963f13cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids are tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]]) \n",
      "\n",
      "and has shape torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Lets decode and print thiese generated tokens, notice how the generated tokens are not the expected ones. We now need a loss function to measure how far off we are from the expected output. The goal is to increase the softmax probability of the expected output tokens.\n",
    "\n",
    "With a vocabulary size of 50257, the chance probability of getting the correct token is 1/50257 = 0.0000199, this is very low."
   ],
   "id": "51e8af7ddeb087b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:02.296237Z",
     "start_time": "2025-09-24T06:03:02.294228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "      f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ],
   "id": "aad66a8bbb21a534",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Remember target is what we expect the model to output. Lets look at the probabilities of these expected tokens in the generated probabilities.\n",
    "\n",
    "probs has shape (2, 3, 50257) and target has shape (2, 3), our goal while training is to increase the probabilities of these expected tokens relative to other tokens."
   ],
   "id": "d7d285e6ea38bd61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:02.316110Z",
     "start_time": "2025-09-24T06:03:02.312986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, torch.arange(targets.shape[1]), targets[text_idx]]\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, torch.arange(targets.shape[1]), targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "print(\"Text 2:\", target_probas_2)\n"
   ],
   "id": "e43ae64d4df6d464",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T05:24:11.676500Z",
     "start_time": "2025-09-15T05:24:11.673130Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "We will next calculate the negative log likelihood loss (NLLLoss) which is commonly used for classification problems\n",
    "\n",
    "![Test](./NLL.png)"
   ],
   "id": "bb3785c26be53f86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:02.330786Z",
     "start_time": "2025-09-24T06:03:02.327696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flatten and compute the log probabilities\n",
    "log_probas = torch.log(torch.cat([target_probas_1, target_probas_2]))\n",
    "print(log_probas)\n",
    "#Compute the average negative log likelihood loss\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)\n",
    "# We always minimise the loss, thus we take the negative, goal is to make this log_probas as close to 0 as possible\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)\n"
   ],
   "id": "81b46f5ee6cd3aac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
      "tensor(-10.7940)\n",
      "tensor(10.7940)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Pytorch has a built in in ``cross_entropy`` loss function which combines the log softmax and ``NLLLoss`` in one function. We will use this to calculate the loss, recall ``logits`` are the raw outputs of the model before applying softmax\n",
    "\n",
    "We will flatten the first two dimensions of the logits"
   ],
   "id": "fa9444575619f32a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:02.348565Z",
     "start_time": "2025-09-24T06:03:02.345255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Logits shape is {logits.shape}\")\n",
    "print(f\"Targets shape is {targets.shape}\")\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(\"Cross entropy loss is:\", loss)\n",
    "print(\"Perplexity: \",torch.exp(loss))"
   ],
   "id": "71673dad5fb9ce5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape is torch.Size([2, 3, 50257])\n",
      "Targets shape is torch.Size([2, 3])\n",
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n",
      "Cross entropy loss is: tensor(10.7940)\n",
      "Perplexity:  tensor(48725.8203)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Perplexity: A common metric for evaluating language models is perplexity, which is the exponentiation of the cross-entropy loss. It provides a measure of how well the model predicts a sample. A lower perplexity indicates a better predictive model. in above case of ``10.790`` perplexity is ``torch.exp(10.7940) = 48725.8203`` which means that the model is unsure of which token to predict next among 48725 tokens, this is close to the chance probability of 50257 tokens\n",
    "\n",
    "Next we will prepare the dataset to train our small model"
   ],
   "id": "438c588aa039dff0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:02.366126Z",
     "start_time": "2025-09-24T06:03:02.361520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = \"./data/the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ],
   "id": "c539a39cd9fda397",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The dataloaders can be visualized as below\n",
    "\n",
    "![test](./Dataloaders.png)"
   ],
   "id": "dc11d6641df794c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:02.379318Z",
     "start_time": "2025-09-24T06:03:02.376426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Recreate the same data loaders we implemented in chapter 2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, text, tokenizer, stride, max_length):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        tokens = tokenizer.encode(text)\n",
    "        for i in range(0, len(tokens) - max_length - 1, stride):\n",
    "            input_id = tokens[i: i + max_length]\n",
    "            target_id = tokens[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_id))\n",
    "            self.target_ids.append(torch.tensor(target_id))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "def create_dataloader_v1(text, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    return DataLoader(dataset=GPTDataset(text=text, tokenizer=tokenizer, stride=stride, max_length=max_length),\n",
    "                      batch_size=batch_size,\n",
    "                      drop_last=drop_last,\n",
    "                      num_workers=num_workers,\n",
    "                      shuffle=shuffle)"
   ],
   "id": "dcdd3187587f13ce",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:02.396491Z",
     "start_time": "2025-09-24T06:03:02.389610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split data in train and validation set and create two data loaders\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n"
   ],
   "id": "cf1cf07a84156a33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T04:41:35.734278Z",
     "start_time": "2025-09-17T04:41:35.732822Z"
    }
   },
   "cell_type": "markdown",
   "source": "Let us now implement the ``cross_entropy`` loss function for our given batch data and then the ``cross_entropy`` for the loader",
   "id": "b1bb5d68603b1022"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:02.407051Z",
     "start_time": "2025-09-24T06:03:02.404488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device) # shape (batch_size, seq_len)\n",
    "    target_batch = target_batch.to(device) # shape (batch_size, seq_len)\n",
    "    logits = model(input_batch) # Generates (logits) of shape (batch_size, seq_len, vocab_size)\n",
    "    return nn.functional.cross_entropy(\n",
    "                logits.flatten(0, 1),   # shape (batch_size * seq_len, vocab_size)\n",
    "                target_batch.flatten()) # shape (batch_size * seq_len)\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    else:\n",
    "        num_batches = len(data_loader) if num_batches is None else min(num_batches, len(data_loader))\n",
    "        for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "            if i < num_batches:\n",
    "                total_loss += calc_loss_batch(input_batch, target_batch, model, device).item()\n",
    "            else:\n",
    "                break\n",
    "        return total_loss / num_batches"
   ],
   "id": "1685fddeac1be530",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lets apply this to test on a model without training",
   "id": "99b841bb916b3412"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:03.161366Z",
     "start_time": "2025-09-24T06:03:02.421381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Train loss:\", train_loss)\n",
    "print(\"Val loss:\", val_loss)\n"
   ],
   "id": "597836020a122843",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Train loss: 10.987583372328016\n",
      "Val loss: 10.98110580444336\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train an LLM\n",
    "\n",
    "With all the nuts and bolts in place we will now train our LLM"
   ],
   "id": "35bdd21ee44390ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:03.172510Z",
     "start_time": "2025-09-24T06:03:03.168262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First define a method that evaluates the model on both train and validation set and returns the training and validation set losses\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "                     model=model, idx=encoded,\n",
    "                     max_new_tokens=50, context_size=context_size\n",
    "                    )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "\n",
    "# Next we will define a simple training loop\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            global_step += 1\n",
    "            tokens_seen += input_batch.numel()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1}, step {global_step:06d}: \"\n",
    "                      f\"train loss {train_loss:.3f}, val loss {val_loss:.3f}, \"\n",
    "                      f\"tokens seen {tokens_seen}\")\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ],
   "id": "891dc384cca2b326",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T05:29:12.154526Z",
     "start_time": "2025-09-19T05:29:12.152537Z"
    }
   },
   "cell_type": "markdown",
   "source": "Now lets initialize and start the training loop",
   "id": "d7e95199c2ec46a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:45.960282Z",
     "start_time": "2025-09-24T06:03:03.183579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW( model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ],
   "id": "5166f33908ad558e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 000000: train loss 9.817, val loss 9.924, tokens seen 512\n",
      "Epoch 1, step 000005: train loss 8.066, val loss 8.332, tokens seen 3072\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Epoch 2, step 000010: train loss 6.619, val loss 7.042, tokens seen 5632\n",
      "Epoch 2, step 000015: train loss 6.046, val loss 6.596, tokens seen 8192\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,, and,, the,, the, and,, and,,, the, and,,,,,,\n",
      "Epoch 3, step 000020: train loss 5.524, val loss 6.508, tokens seen 10752\n",
      "Epoch 3, step 000025: train loss 5.369, val loss 6.378, tokens seen 13312\n",
      "Every effort moves you, and to the of the of the picture. Gis.                                     \n",
      "Epoch 4, step 000030: train loss 4.830, val loss 6.263, tokens seen 15872\n",
      "Epoch 4, step 000035: train loss 4.586, val loss 6.285, tokens seen 18432\n",
      "Every effort moves you of the \"I the picture.                    \"I\"I the picture\"I had the picture\"I the picture and I had been the picture of\n",
      "Epoch 5, step 000040: train loss 3.879, val loss 6.130, tokens seen 20992\n",
      "Every effort moves you know he had been his pictures, and I felt it's by his last word.                   \"Oh, and he had been the end, and he had been\n",
      "Epoch 6, step 000045: train loss 3.530, val loss 6.183, tokens seen 23552\n",
      "Epoch 6, step 000050: train loss 2.960, val loss 6.123, tokens seen 26112\n",
      "Every effort moves you know it was his pictures--I glanced after him, I had the last word.        \"Oh, and I was his pictures--I looked.   \"I looked. \"I looked. \n",
      "Epoch 7, step 000055: train loss 2.832, val loss 6.150, tokens seen 28672\n",
      "Epoch 7, step 000060: train loss 2.104, val loss 6.133, tokens seen 31232\n",
      "Every effort moves you know the picture to me--I glanced after him, and Mrs.  \"I was no great, the fact, the fact that, the moment--as Jack himself, as his pictures--as of the picture--because he was a little\n",
      "Epoch 8, step 000065: train loss 1.691, val loss 6.186, tokens seen 33792\n",
      "Epoch 8, step 000070: train loss 1.391, val loss 6.230, tokens seen 36352\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a little: \"Yes--and by me to me to have to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Epoch 9, step 000075: train loss 1.059, val loss 6.251, tokens seen 38912\n",
      "Epoch 9, step 000080: train loss 0.800, val loss 6.278, tokens seen 41472\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back the window-curtains, I saw that, and down the room, and now\n",
      "Epoch 10, step 000085: train loss 0.569, val loss 6.373, tokens seen 44032\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:46.316948Z",
     "start_time": "2025-09-24T06:03:45.975223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
   ],
   "id": "544c7ce8f407ca15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Once we get past second epoch we can see that the model is able to generate meaningful text. The training and validation losses are also decreasing, indicating that the model is learning. But after epoch 2, validation loss starts to increase, indicating overfitting. This is expected as we are training a large model on a small dataset.\n",
    "\n",
    "Lets put the model back on cpu and run some sample text generation. Also, we will look at a concept called temperature scaling"
   ],
   "id": "8a598367ab187c3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:47.853790Z",
     "start_time": "2025-09-24T06:03:46.323351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "c1f7bf2d2852f5a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:47.879672Z",
     "start_time": "2025-09-24T06:03:47.875369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lets consider this vocab again\n",
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "# We expect the index 3 (forward) to have the highest probability\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])\n",
    "\n",
    "# If we repeat this experiment 100 times, each time the output will be the same\n",
    "for _ in range(100):\n",
    "    next_token_id = torch.argmax(probas).item()\n",
    "    assert next_token_id == 3"
   ],
   "id": "6d2ee6f7ffdb8848",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "|Let's first look at what multinomial sampling is\n",
   "id": "bf8eea5fcec14a26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:47.902765Z",
     "start_time": "2025-09-24T06:03:47.893801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "# Define probabilities for 4 categories, image this is a 4 faced die with each face has a different probability\n",
    "weights = torch.tensor([0.1, 0.2, 0.3, 0.4])\n",
    "\n",
    "# Draw 100,000 samples from this distribution with replacement\n",
    "samples_drawn = torch.multinomial(weights, 100000, replacement=True).tolist()\n",
    "counts_by_face = Counter(samples_drawn)\n",
    "print(\"Counts by face:\")\n",
    "for face, count in sorted(counts_by_face.items()):\n",
    "    print(f\"\\tFace {face}: {count/len(samples_drawn):.2f}\")\n",
    "# We see the simulated probabilities are close to the original weights"
   ],
   "id": "10209d29a0c07213",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by face:\n",
      "\tFace 0: 0.10\n",
      "\tFace 1: 0.20\n",
      "\tFace 2: 0.30\n",
      "\tFace 3: 0.40\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now that we saw what multinomial sampling is, what we do next is use the probabilities of the next sample token and use multinomial sampling to select the next token. This will add some randomness unlike the previous approach where we used ``argmax`` which deterministically selected the next token with the highest probability.\n",
    "\n",
    "We now know the probability of selection is directly proportional to the weight of each token."
   ],
   "id": "93c402b31a54ebf8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:47.934409Z",
     "start_time": "2025-09-24T06:03:47.912531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_sampled_token(probas):\n",
    "    torch.manual_seed(123)\n",
    "    samples = torch.tensor([torch.multinomial(probas, num_samples = 1) for _ in range(1000)])\n",
    "    sampled_ids = torch.bincount(samples)\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_token(probas)\n",
    "\n",
    "# While forward is still most likely token, the other tokens also get selected sometimes\n",
    "# in the same proportion as their probabilities"
   ],
   "id": "d86e76ef665a632",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will use an additional parameter temperature to control the randomness of the sampling. A higher temperature will make the distribution more uniform, while a lower temperature will make the distribution more peaked.",
   "id": "8d35fdf36bd18eaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:48.006732Z",
     "start_time": "2025-09-24T06:03:47.940904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
    "                for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "65717843c847fa62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we see above, when the temperature is 0.1 (low), the distribution is very peaked, meaning the model is very confident about its prediction with \"forward\" predicted almost always. When the temperature is 5 (high), the distribution is more uniform, meaning the model is less confident about its prediction.\n",
    "\n",
    "\n",
    "TODO: Ex 5.1\n",
    "\n",
    "We will now look at Top-k sampling\n",
    "\n",
    "### Top-k Sampling\n",
    "\n",
    "By increasing the temperature, we make the distribution more uniform, but this can lead to selecting very low probability tokens which may not make sense in the context. To avoid this, we can use Top-k sampling, where we only consider the top k tokens with the highest probabilities and set the rest to zero. This way, we limit the selection to a smaller set of likely tokens.\n",
    "\n",
    "Following image summarizes this idea.\n",
    "\n",
    "![Test](./Top-k.png)\n"
   ],
   "id": "fe9b552084e02bd3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:48.017600Z",
     "start_time": "2025-09-24T06:03:48.013612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)\n",
    "# Following line is more memory efficient but it modifies the original next_token_logits tensor\n",
    "#next_token_logits[next_token_logits < top_logits[-1]] = torch.tensor(float('-inf'))\n",
    "\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input = torch.tensor(float('-inf')),\n",
    "    other = next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)\n"
   ],
   "id": "a55fd438654aee2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n",
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we will modify the ``generate`` function to include the temperature and top-k sampling\n",
   "id": "1ae7221a319fd7b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:48.035809Z",
     "start_time": "2025-09-24T06:03:48.032801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)   # (b, context_size, vocab_size)\n",
    "        logits = logits[:, -1, :]      # (b, vocab_size)\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_k_logits, _ = torch.topk(logits, top_k)  # (b, top_k)\n",
    "            min_val = top_k_logits[:, -1]                # (b,)\n",
    "            logits[logits < min_val] = torch.tensor(float('-inf')).to(logits.device)\n",
    "            #logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "        if temperature > 0:\n",
    "            probs = torch.softmax(logits / temperature, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        else:\n",
    "            idx = torch.cat((idx, idx_next), dim=-1)\n",
    "\n",
    "    return idx\n"
   ],
   "id": "badb93053ea62d5f",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:48.813032Z",
     "start_time": "2025-09-24T06:03:48.048914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "38f18c3c68537bee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand,\" she down.\" For Mrs. Gisburn! The women had\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T04:37:03.792191Z",
     "start_time": "2025-09-22T04:37:03.790386Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "TODO: Look at Ex 5.2 and 5.3\n",
    "\n",
    "## Loading and saving model weights in PyTorch\n",
    "\n",
    "Now we will not train the model from scratch, instead we will load the weights of a pretrained model.\n",
    "\n",
    "First we will simply save the existing model and optimizer weights in a ``.pth`` file. This is the file for PyTorch format"
   ],
   "id": "4eafcd2de30238fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:51.339835Z",
     "start_time": "2025-09-24T06:03:48.818716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save({\n",
    " \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict()\n",
    "}, \"model_and_optimizer.pth\")\n"
   ],
   "id": "7ce87e1148e5dd2a",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:53.956157Z",
     "start_time": "2025-09-24T06:03:51.364069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.eval()\n",
    "#Lets test the previously generated output\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "3efc0844a8f6c827",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand,\" she down.\" For Mrs. Gisburn! The women had\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:03:54.640680Z",
     "start_time": "2025-09-24T06:03:54.633847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download the Python code that will download the GPT2 weights\n",
    "import requests\n",
    "import os\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "if not os.path.exists(filename):\n",
    "    response = requests.get(url)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)"
   ],
   "id": "5c4adee3d545a4cc",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:09:41.228632Z",
     "start_time": "2025-09-24T06:07:09.899721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gpt_download\n",
    "import importlib\n",
    "importlib.reload(gpt_download)\n",
    "settings, params = gpt_download.download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ],
   "id": "421dd885d7d5cc50",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 77.9kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 890kiB/s] \n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 74.8kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [02:16<00:00, 3.65MiB/s]   \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 3.32MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 504kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 500kiB/s]  \n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T06:09:41.251263Z",
     "start_time": "2025-09-24T06:09:41.248557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ],
   "id": "8f11516a71b92ddf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dbabac7fe58b8746"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
